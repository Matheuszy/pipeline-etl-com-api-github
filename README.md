# ğŸš€ Pipeline ETL - GitHub API

## ğŸ“‹ DescriÃ§Ã£o

Este projeto implementa uma **pipeline ETL (Extract, Transform, Load)** utilizando a API do GitHub, desenvolvido com foco na prÃ¡tica de **ProgramaÃ§Ã£o Orientada a Objetos (POO)** em Python para especializaÃ§Ã£o em **Engenharia de Dados**.

## ğŸ¯ Objetivos

- **Praticar POO**: Implementar conceitos de orientaÃ§Ã£o a objetos (heranÃ§a, encapsulamento, polimorfismo, abstraÃ§Ã£o)
- **Desenvolver Pipeline ETL**: Criar um fluxo completo de extraÃ§Ã£o, transformaÃ§Ã£o e carregamento de dados
- **Integrar com GitHub API**: Consumir dados da API pÃºblica do GitHub
- **Aplicar Boas PrÃ¡ticas**: Seguir padrÃµes de cÃ³digo limpo e arquitetura modular
- **EspecializaÃ§Ã£o em Engenharia de Dados**: Aplicar conceitos fundamentais da Ã¡rea

## ğŸ—ï¸ Arquitetura do Projeto

```
projeto_engenharia_de_dados/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ extract/          # Camada de ExtraÃ§Ã£o
â”‚   â”‚   â””â”€â”€ data_extraction.py
â”‚   â”œâ”€â”€ transform/        # Camada de TransformaÃ§Ã£o
â”‚   â”‚   â””â”€â”€ data_transform.py
â”‚   â””â”€â”€ load/            # Camada de Carregamento
â”‚       â””â”€â”€ data_load.py
â”œâ”€â”€ requirements.txt      # DependÃªncias do projeto
â””â”€â”€ README.md
```

## ğŸ”§ Tecnologias Utilizadas

- **Python 3.x**
- **GitHub API** - Para extraÃ§Ã£o de dados
- **Pandas** - ManipulaÃ§Ã£o e anÃ¡lise de dados
- **NumPy** - ComputaÃ§Ã£o numÃ©rica
- **Requests** - RequisiÃ§Ãµes HTTP para API

## ğŸ“¦ DependÃªncias

```bash
pip install -r requirements.txt
```

### Principais Bibliotecas:
- `requests==2.28.2` - Cliente HTTP para consumir a API do GitHub
- `pandas==2.0.0` - ManipulaÃ§Ã£o e anÃ¡lise de dados
- `numpy==2.2.6` - ComputaÃ§Ã£o numÃ©rica
- `certifi==2025.8.3` - Certificados SSL/TLS

## ğŸ¨ PadrÃµes de POO Implementados

### 1. **AbstraÃ§Ã£o**
- Classes abstratas para definir contratos de ETL
- Interfaces claras entre as camadas

### 2. **Encapsulamento**
- MÃ©todos privados para lÃ³gica interna
- Propriedades pÃºblicas para acesso controlado aos dados

### 3. **HeranÃ§a**
- Hierarquia de classes para diferentes tipos de extraÃ§Ã£o
- ReutilizaÃ§Ã£o de cÃ³digo comum

### 4. **Polimorfismo**
- MÃºltiplas implementaÃ§Ãµes para diferentes fontes de dados
- Comportamento flexÃ­vel baseado no tipo de objeto

## ğŸ”„ Fluxo da Pipeline ETL

### **Extract (ExtraÃ§Ã£o)**
- ConexÃ£o com a API do GitHub
- Coleta de dados de repositÃ³rios, usuÃ¡rios, issues, etc.
- Tratamento de rate limiting e autenticaÃ§Ã£o

### **Transform (TransformaÃ§Ã£o)**
- Limpeza e validaÃ§Ã£o dos dados
- AgregaÃ§Ãµes e cÃ¡lculos
- NormalizaÃ§Ã£o de estruturas

### **Load (Carregamento)**
- PersistÃªncia em diferentes formatos
- EstruturaÃ§Ã£o para anÃ¡lise posterior

## ğŸš€ Como Executar

1. **Clone o repositÃ³rio**
```bash
git clone <url-do-repositorio>
cd projeto_engenharia_de_dados
```

2. **Instale as dependÃªncias**
```bash
pip install -r requirements.txt
```

3. **Configure as variÃ¡veis de ambiente** (se necessÃ¡rio)
```bash
export GITHUB_TOKEN=seu_token_aqui
```

4. **Execute a pipeline**
```bash
python src/main.py
```

## ğŸ“Š Exemplos de Uso

### ExtraÃ§Ã£o de Dados
```python
from src.extract.data_extraction import GitHubDataExtractor

extractor = GitHubDataExtractor()
repos_data = extractor.extract_repositories("username")
```

### TransformaÃ§Ã£o de Dados
```python
from src.transform.data_transform import DataTransformer

transformer = DataTransformer()
clean_data = transformer.clean_repository_data(repos_data)
```

### Carregamento de Dados
```python
from src.load.data_load import DataLoader

loader = DataLoader()
loader.save_to_csv(clean_data, "repositories.csv")
```

## ğŸ“ Conceitos de Engenharia de Dados Aplicados

- **Data Pipeline**: Fluxo estruturado de processamento de dados
- **API Integration**: Consumo de APIs externas para coleta de dados
- **Data Quality**: ValidaÃ§Ã£o e limpeza de dados
- **Modular Architecture**: SeparaÃ§Ã£o clara de responsabilidades
- **Error Handling**: Tratamento robusto de erros e exceÃ§Ãµes
- **Logging**: Rastreamento de execuÃ§Ã£o e debugging

## ğŸ” Estrutura das Classes

### `GitHubDataExtractor`
- ResponsÃ¡vel pela extraÃ§Ã£o de dados da API do GitHub
- Implementa mÃ©todos para diferentes tipos de dados
- Gerencia autenticaÃ§Ã£o e rate limiting

### `DataTransformer`
- Processa e transforma os dados extraÃ­dos
- Aplica regras de negÃ³cio e validaÃ§Ãµes
- Prepara dados para carregamento

### `DataLoader`
- Persiste dados em diferentes formatos
- Gerencia conexÃµes com sistemas de armazenamento
- Implementa estratÃ©gias de backup e versionamento

## ğŸ“ˆ PrÃ³ximos Passos

- [ ] Implementar autenticaÃ§Ã£o OAuth para GitHub
- [ ] Adicionar suporte a mÃºltiplas fontes de dados
- [ ] Implementar cache para otimizaÃ§Ã£o de performance
- [ ] Adicionar testes unitÃ¡rios e de integraÃ§Ã£o
- [ ] Implementar monitoramento e alertas
- [ ] Adicionar suporte a streaming de dados
- [ ] Implementar paralelizaÃ§Ã£o para processamento

## ğŸ¤ ContribuiÃ§Ã£o

Este projeto Ã© focado no aprendizado e prÃ¡tica. Sinta-se Ã  vontade para:

- Reportar bugs
- Sugerir melhorias
- Implementar novas funcionalidades
- Compartilhar conhecimento

## ğŸ“š Recursos de Aprendizado

- [GitHub API Documentation](https://docs.github.com/en/rest)
- [Python POO Tutorial](https://docs.python.org/3/tutorial/classes.html)
- [Pandas Documentation](https://pandas.pydata.org/docs/)
- [Engenharia de Dados - Conceitos Fundamentais](https://www.databricks.com/glossary/data-engineering)

## ğŸ“„ LicenÃ§a

Este projeto Ã© desenvolvido para fins educacionais e de prÃ¡tica profissional.

---

**Desenvolvido com â¤ï¸ para especializaÃ§Ã£o em Engenharia de Dados**
